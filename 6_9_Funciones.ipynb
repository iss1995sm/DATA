{"cells":[{"cell_type":"markdown","source":["# Funciones"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3742e202-4e5a-4c3d-990a-b520bbe56881"}}},{"cell_type":"code","source":["from pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62399443-ca3a-475c-8651-dae22b54c873"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Fechas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"392e1c0c-1108-4f22-b752-7d2d48dc8362"}}},{"cell_type":"code","source":["from pyspark.sql.functions import to_date\n\n# Obtenemos el dataFrame a partir del fichero pdi_sales_small.csv\ndf = spark.read.option(\"sep\",\";\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/FileStore/tables/pdi_sales_small.csv\")\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e7899f2-703f-4150-bc41-4f84db39df53"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- ProductID: integer (nullable = true)\n |-- Date: string (nullable = true)\n |-- Zip: string (nullable = true)\n |-- Units: integer (nullable = true)\n |-- Revenue: double (nullable = true)\n |-- Country: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- ProductID: integer (nullable = true)\n |-- Date: string (nullable = true)\n |-- Zip: string (nullable = true)\n |-- Units: integer (nullable = true)\n |-- Revenue: double (nullable = true)\n |-- Country: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Cambiamos el tipo de dato a la fecha\ndf = df.withColumn(\"Date\", to_date(df.Date, \"M/d/yyy\"))\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a467899-7451-478e-b97b-dd57e9efd4b4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- ProductID: integer (nullable = true)\n |-- Date: date (nullable = true)\n |-- Zip: string (nullable = true)\n |-- Units: integer (nullable = true)\n |-- Revenue: double (nullable = true)\n |-- Country: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- ProductID: integer (nullable = true)\n |-- Date: date (nullable = true)\n |-- Zip: string (nullable = true)\n |-- Units: integer (nullable = true)\n |-- Revenue: double (nullable = true)\n |-- Country: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e55697d7-c5c7-4c48-a38d-a73367e887ea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+----------+---------------+-----+-------+-------+\n|ProductID|      Date|            Zip|Units|Revenue|Country|\n+---------+----------+---------------+-----+-------+-------+\n|      725|1999-01-15|41540          |    1|  115.5|Germany|\n|      787|2002-06-06|41540          |    1|  314.9|Germany|\n|      788|2002-06-06|41540          |    1|  314.9|Germany|\n|      940|1999-01-15|22587          |    1|  687.7|Germany|\n|      396|1999-01-15|22587          |    1|  857.1|Germany|\n+---------+----------+---------------+-----+-------+-------+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+----------+---------------+-----+-------+-------+\n|ProductID|      Date|            Zip|Units|Revenue|Country|\n+---------+----------+---------------+-----+-------+-------+\n|      725|1999-01-15|41540          |    1|  115.5|Germany|\n|      787|2002-06-06|41540          |    1|  314.9|Germany|\n|      788|2002-06-06|41540          |    1|  314.9|Germany|\n|      940|1999-01-15|22587          |    1|  687.7|Germany|\n|      396|1999-01-15|22587          |    1|  857.1|Germany|\n+---------+----------+---------------+-----+-------+-------+\nonly showing top 5 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(\"Date\", date_format(\"Date\", \"dd-MM-yyy\"),\n         next_day(\"Date\", \"Sun\"), last_day(\"Date\"),\n            dayofmonth(\"Date\"), dayofyear(\"Date\"),\n            month(\"Date\"), year(\"Date\")).show(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19c259a7-fb7e-439c-925e-3ba4291be1a0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+\n|      Date|date_format(Date, dd-MM-yyy)|next_day(Date, Sun)|last_day(Date)|dayofmonth(Date)|dayofyear(Date)|month(Date)|year(Date)|\n+----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+\n|1999-01-15|                  15-01-1999|         1999-01-17|    1999-01-31|              15|             15|          1|      1999|\n|2002-06-06|                  06-06-2002|         2002-06-09|    2002-06-30|               6|            157|          6|      2002|\n+----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+\nonly showing top 2 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+\n|      Date|date_format(Date, dd-MM-yyy)|next_day(Date, Sun)|last_day(Date)|dayofmonth(Date)|dayofyear(Date)|month(Date)|year(Date)|\n+----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+\n|1999-01-15|                  15-01-1999|         1999-01-17|    1999-01-31|              15|             15|          1|      1999|\n|2002-06-06|                  06-06-2002|         2002-06-09|    2002-06-30|               6|            157|          6|      2002|\n+----------+----------------------------+-------------------+--------------+----------------+---------------+-----------+----------+\nonly showing top 2 rows\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Cadenas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cccc0aa4-e590-4660-849d-26efe36f889f"}}},{"cell_type":"code","source":["# Operaciones con cadenas de caracteres, eliminación de espacios, minúsculas o mayúsculas sobre filas de Canada\ndf.select(\"Zip\", ltrim(\"Zip\").alias(\"l\"), rtrim(\"Zip\").alias(\"r\"), \n         lower(\"Zip\"), upper(\"Zip\")\n         ).where(trim(df.Country)==\"Canada\").show(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"712011ee-7c1a-4959-8fb2-e78370e30185"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------------+---------------+---+---------------+---------------+\n|            Zip|              l|  r|     lower(Zip)|     upper(Zip)|\n+---------------+---------------+---+---------------+---------------+\n|H1B            |H1B            |H1B|h1b            |H1B            |\n|H1B            |H1B            |H1B|h1b            |H1B            |\n|H1B            |H1B            |H1B|h1b            |H1B            |\n+---------------+---------------+---+---------------+---------------+\nonly showing top 3 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------------+---------------+---+---------------+---------------+\n|            Zip|              l|  r|     lower(Zip)|     upper(Zip)|\n+---------------+---------------+---+---------------+---------------+\n|H1B            |H1B            |H1B|h1b            |H1B            |\n|H1B            |H1B            |H1B|h1b            |H1B            |\n|H1B            |H1B            |H1B|h1b            |H1B            |\n+---------------+---------------+---+---------------+---------------+\nonly showing top 3 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Más operaciones con cadenas de caracteres\ndf.select(\"Country\", initcap(\"Country\"), reverse(\"Country\"),\n          length(\"Country\"), translate(\"Country\", \"na\", \"pe\")\n         ).where(trim(df.Country)==\"Canada\").show(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d3777c1-7d4f-4cc2-a2fb-f0500bb26bd4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+----------------+----------------+---------------+--------------------------+\n|Country|initcap(Country)|reverse(Country)|length(Country)|translate(Country, na, pe)|\n+-------+----------------+----------------+---------------+--------------------------+\n|Canada |         Canada |          adanaC|              7|                   Cepede |\n|Canada |         Canada |          adanaC|              7|                   Cepede |\n|Canada |         Canada |          adanaC|              7|                   Cepede |\n+-------+----------------+----------------+---------------+--------------------------+\nonly showing top 3 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+----------------+----------------+---------------+--------------------------+\n|Country|initcap(Country)|reverse(Country)|length(Country)|translate(Country, na, pe)|\n+-------+----------------+----------------+---------------+--------------------------+\n|Canada |         Canada |          adanaC|              7|                   Cepede |\n|Canada |         Canada |          adanaC|              7|                   Cepede |\n|Canada |         Canada |          adanaC|              7|                   Cepede |\n+-------+----------------+----------------+---------------+--------------------------+\nonly showing top 3 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Operaciones con subcadenas\ndf.select(\"Country\", split(\"Country\", \"a\"), locate(\"a\", \"Country\"),\n          substring(\"Country\",3,2)\n         ).where(trim(df.Country)==\"Canada\").show(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"79961955-0951-4822-b3f9-ffa8d3f680d7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+---------------------+---------------------+------------------------+\n|Country|split(Country, a, -1)|locate(a, Country, 1)|substring(Country, 3, 2)|\n+-------+---------------------+---------------------+------------------------+\n|Canada |         [C, n, d,  ]|                    2|                      na|\n|Canada |         [C, n, d,  ]|                    2|                      na|\n|Canada |         [C, n, d,  ]|                    2|                      na|\n+-------+---------------------+---------------------+------------------------+\nonly showing top 3 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+---------------------+---------------------+------------------------+\n|Country|split(Country, a, -1)|locate(a, Country, 1)|substring(Country, 3, 2)|\n+-------+---------------------+---------------------+------------------------+\n|Canada |         [C, n, d,  ]|                    2|                      na|\n|Canada |         [C, n, d,  ]|                    2|                      na|\n|Canada |         [C, n, d,  ]|                    2|                      na|\n+-------+---------------------+---------------------+------------------------+\nonly showing top 3 rows\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Colecciones"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec15f2b0-0b3f-4e99-9974-77775e6dc7b6"}}},{"cell_type":"markdown","source":["Para trabajar con colecciones vamos a usar el fichero _yelp_academic_dataset_business.json_ con datos de negocio de la empresa **Yelp** publicados para uso académico.\n\nLos negocios tienen una propiedad denominada _categories_ que contiene un array con las categorías de los mismos."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"512e5109-dec4-4954-852c-a09ed7fda33a"}}},{"cell_type":"code","source":["# Aunque con esta sentencia se obtiene sólo el primer registro del archivo, es válido para ver el funcionamiento de las colecciones\n\ndf = spark.read.option(\"inferSchema\", \"true\").option(\"multiline\",True).json(\"/FileStore/tables/yelp_business.json\")\n\n# df = spark.read.json(\"/FileStore/tables/yelp_academic_dataset_business.json\")\n\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6255eec1-1587-4008-a53e-b200c718e47f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- attributes: struct (nullable = true)\n |    |-- Good for Kids: boolean (nullable = true)\n |-- business_id: string (nullable = true)\n |-- categories: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- city: string (nullable = true)\n |-- full_address: string (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- name: string (nullable = true)\n |-- neighborhoods: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- open: boolean (nullable = true)\n |-- review_count: long (nullable = true)\n |-- stars: double (nullable = true)\n |-- state: string (nullable = true)\n |-- type: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- attributes: struct (nullable = true)\n |    |-- Good for Kids: boolean (nullable = true)\n |-- business_id: string (nullable = true)\n |-- categories: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- city: string (nullable = true)\n |-- full_address: string (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- name: string (nullable = true)\n |-- neighborhoods: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- open: boolean (nullable = true)\n |-- review_count: long (nullable = true)\n |-- stars: double (nullable = true)\n |-- state: string (nullable = true)\n |-- type: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fafe324e-1871-413e-b0a8-14b1a8f8d4d1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[13]: 1","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[13]: 1"]}}],"execution_count":0},{"cell_type":"markdown","source":["Realizamos una consulta sobre los datos del fichero siguiendo el esquema del dataframe.\n\nObtenemos el nombre, el horario de los domingos utilizando la notación '.' para acceder a los campos anidados,\nla cantidad de categorías de cada comercio, un listado ordenado con sus categorías y si es un restaurante."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cfd6d075-2120-43df-8e5f-cd12ca670d2f"}}},{"cell_type":"code","source":["df.select(\"name\", size(\"categories\").alias(\"totalCategorias\"),\n               sort_array(\"categories\").alias(\"categorias\"),\n               array_contains(\"categories\", \"Restaurants\").alias(\"Restaurantes\")).show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e7d6a10d-b4c6-4dde-80c3-993b7c598da1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+---------------+--------------------+------------+\n|                name|totalCategorias|          categorias|Restaurantes|\n+--------------------+---------------+--------------------+------------+\n|Shauna Brown Fitness|              5|[Active Life, Fit...|       false|\n+--------------------+---------------+--------------------+------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+---------------+--------------------+------------+\n|                name|totalCategorias|          categorias|Restaurantes|\n+--------------------+---------------+--------------------+------------+\n|Shauna Brown Fitness|              5|[Active Life, Fit...|       false|\n+--------------------+---------------+--------------------+------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.select(\"name\", explode(\"categories\")).show(10, truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff735196-b501-49da-bc4d-4507efe12eac"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+---------------------+\n|name                |col                  |\n+--------------------+---------------------+\n|Shauna Brown Fitness|Active Life          |\n|Shauna Brown Fitness|Massage Therapy      |\n|Shauna Brown Fitness|Health & Medical     |\n|Shauna Brown Fitness|Trainers             |\n|Shauna Brown Fitness|Fitness & Instruction|\n+--------------------+---------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+---------------------+\n|name                |col                  |\n+--------------------+---------------------+\n|Shauna Brown Fitness|Active Life          |\n|Shauna Brown Fitness|Massage Therapy      |\n|Shauna Brown Fitness|Health & Medical     |\n|Shauna Brown Fitness|Trainers             |\n|Shauna Brown Fitness|Fitness & Instruction|\n+--------------------+---------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Datos JSON"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1fc0141b-59e0-4b73-bd0c-489234f9b302"}}},{"cell_type":"markdown","source":["Las siguientes celdas muestran cómo transformar una colección obtenida desde datos creados como RDD a un DataFrame definido como JSON.\n\nPara ello hay que crear el esquema de los datos JSON y con éste transformarlo con la función _from_json_"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"896c0fd1-7cfd-4d41-acb1-b219319cb861"}}},{"cell_type":"code","source":["tareas = [\"\"\"{\"dia\": \"Lunes\", \"tareas\": [\"Corregir ejercicios\", \"Ir a nadar\", \"Comprar pan\"]}\"\"\"]\n# ['{\"dia\": \"Lunes\", \"tareas\": [\"Corregir ejercicios\", \"Ir a nadar\", \"Comprar pan\"]}']\ntareasRDD = spark.sparkContext.parallelize(tareas)\n# tareasStrDF es un DF con una columna con nombre value de tipo string\ntareasStrDF = tareasRDD.toDF(\"string\")\ntareasStrDF.printSchema()\ntareasStrDF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25ddff9f-2d2a-495c-949d-ce3751f8940f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- value: string (nullable = true)\n\n+--------------------+\n|               value|\n+--------------------+\n|{\"dia\": \"Lunes\", ...|\n+--------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- value: string (nullable = true)\n\n+--------------------+\n|               value|\n+--------------------+\n|{\"dia\": \"Lunes\", ...|\n+--------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Se quiere pasar el DataFrame a JSON.\n# Lo primero es definir el esquema de la estructura JSON\nfrom pyspark.sql.types import StructType, StructField, StringType, ArrayType\n\nesquemaTareas = StructType([\n    StructField(\"dia\", StringType(), False),\n    StructField(\"tareas\", ArrayType(StringType(), False), False)\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c248a8b-689d-44b3-a111-4481bf57817b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Transformamos el DF al formato JSON\ntodosDF = tareasStrDF.select(from_json(\"value\", esquemaTareas).alias(\"datos\"))\ntodosDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7210d786-a880-4931-9d94-545b1db76a77"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- datos: struct (nullable = true)\n |    |-- dia: string (nullable = true)\n |    |-- tareas: array (nullable = true)\n |    |    |-- element: string (containsNull = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- datos: struct (nullable = true)\n |    |-- dia: string (nullable = true)\n |    |-- tareas: array (nullable = true)\n |    |    |-- element: string (containsNull = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Acceso a los datos\n# Un elemento de una columna\ntodosDF.select(col(\"datos\").getItem(\"dia\"),\n     \"datos.tareas\",\n     (todosDF.datos.getItem(\"tareas\")[0]).alias(\"tarea1\")).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f0bdfe13-9992-47de-87d2-a457262f94c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+----------------------------------------------+-------------------+\n|datos.dia|tareas                                        |tarea1             |\n+---------+----------------------------------------------+-------------------+\n|Lunes    |[Corregir ejercicios, Ir a nadar, Comprar pan]|Corregir ejercicios|\n+---------+----------------------------------------------+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+----------------------------------------------+-------------------+\n|datos.dia|tareas                                        |tarea1             |\n+---------+----------------------------------------------+-------------------+\n|Lunes    |[Corregir ejercicios, Ir a nadar, Comprar pan]|Corregir ejercicios|\n+---------+----------------------------------------------+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Representación JSON de una columna\ntodosDF.select(to_json(\"datos\")).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13470a50-9e69-40cc-af69-cbc219268bb4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------------------------------------------------------------------------+\n|to_json(datos)                                                             |\n+---------------------------------------------------------------------------+\n|{\"dia\":\"Lunes\",\"tareas\":[\"Corregir ejercicios\",\"Ir a nadar\",\"Comprar pan\"]}|\n+---------------------------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------------------------------------------------------------------------+\n|to_json(datos)                                                             |\n+---------------------------------------------------------------------------+\n|{\"dia\":\"Lunes\",\"tareas\":[\"Corregir ejercicios\",\"Ir a nadar\",\"Comprar pan\"]}|\n+---------------------------------------------------------------------------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"6_9_Funciones","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3950083178448067}},"nbformat":4,"nbformat_minor":0}
